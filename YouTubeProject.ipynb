{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### Apologies for the state of this code. It has just been cobbled together as we all worked independently on our local devices and then\n",
        "### combined at the presentation stage."
      ],
      "metadata": {
        "id": "cCTbDaecVv5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from googleapiclient.discovery import build\n",
        "import time\n",
        "import dateutil"
      ],
      "metadata": {
        "id": "r-nVk_wTT355"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_key = 'your_api_key_here'\n",
        "\n",
        "#creates a service object: youtube\n",
        "youtube = build('youtube','v3',developerKey=my_key)\n",
        "\n",
        "# all region code fyi\n",
        "'''\n",
        "region_codes = [\n",
        "    'US', 'GB', 'CA', 'FR', 'DE', 'JP', 'IN', 'BR', 'RU', 'MX',\n",
        "    'KR', 'AU', 'IT', 'ES', 'NL', 'SE', 'CH', 'AR', 'BE', 'AT',\n",
        "    'DK', 'FI', 'NO', 'PL', 'PT', 'CZ', 'HU', 'IE', 'NZ', 'SG',\n",
        "    'MY', 'PH', 'TH', 'TW', 'VN', 'IL', 'SA', 'AE', 'ZA', 'EG',\n",
        "    'TR', 'GR', 'RO', 'BG', 'HR', 'SI', 'SK', 'LT', 'LV', 'EE',\n",
        "    'ID', 'PK', 'NG', 'KE', 'CO', 'CL', 'PE', 'UY', 'VE', 'DZ'\n",
        "]\n",
        "'''"
      ],
      "metadata": {
        "id": "ZWKf7Y85UICm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_videos(region_codes):\n",
        "\n",
        "    filtered_videos = {\n",
        "            'videoID': [],\n",
        "            'title': [],\n",
        "            'views_count': [],\n",
        "            'duration': [],\n",
        "            'pushlishAt': [],\n",
        "            'channelID': [],\n",
        "            'description': [],\n",
        "            'region':[],\n",
        "            'categoryID':[]\n",
        "        }\n",
        "\n",
        "    for region in region_codes:\n",
        "        response = youtube.videos().list(\n",
        "                part=\"snippet,statistics,contentDetails\",\n",
        "                chart=\"mostPopular\",\n",
        "                regionCode=region,\n",
        "                maxResults=50\n",
        "            ).execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            duration = item['contentDetails']['duration']\n",
        "            if duration.startswith('PT') and 'M' not in duration and 'H' not in duration:\n",
        "                continue\n",
        "\n",
        "            filtered_videos['videoID'].append(item['id'])\n",
        "            filtered_videos['title'].append(item['snippet']['title'])\n",
        "            filtered_videos['views_count'].append(int(item['statistics'].get('viewCount', 0)))\n",
        "            filtered_videos['duration'].append(duration)\n",
        "            filtered_videos['pushlishAt'].append(item['snippet']['publishedAt'])\n",
        "            filtered_videos['channelID'].append(item['snippet']['channelId'])\n",
        "            filtered_videos['description'].append(item['snippet']['description'])\n",
        "            filtered_videos['region'].append(region)\n",
        "            filtered_videos['categoryID'].append(item['snippet']['categoryId'])\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(filtered_videos)\n",
        "    return df"
      ],
      "metadata": {
        "id": "JRunx97qULVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_code = ['US', 'GB', 'CA', 'FR', 'DE', 'JP', 'IN', 'BR', 'RU', 'MX',\n",
        "    'KR', 'AU', 'IT', 'ES', 'NL', 'SE', 'CH', 'AR', 'BE', 'AT']\n",
        "df = get_videos(region_code)\n",
        "\n",
        "# df.to_csv('20 country_Yue.csv')\n",
        "\n",
        "df_Yue = pd.read_csv('20 country_Yue.csv')\n",
        "df_Lewis = pd.read_csv('lewis_new_20_country.csv')\n",
        "df_Teresa = pd.read_csv('20countries_new_Teresa.csv')\n",
        "\n",
        "df_final = pd.concat([df_Yue,df_Lewis,df_Teresa],ignore_index=True)\n",
        "df_final.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "\n",
        "# df_final.to_csv(\"All videos.csv\")\n",
        "df_final.shape"
      ],
      "metadata": {
        "id": "aEash9gqUOQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_category_mapping():\n",
        "     category_IDs = {'id':[],'category_name':[]}\n",
        "     response = youtube.videoCategories().list(\n",
        "                                   part = \"snippet\",\n",
        "                              regionCode = 'US'\n",
        "                         ).execute()\n",
        "\n",
        "     for item in response['items']:\n",
        "          category_IDs['id'].append(item['id'])\n",
        "          category_IDs['category_name'].append(item['snippet']['title'])\n",
        "\n",
        "     df = pd.DataFrame(category_IDs)\n",
        "     return df\n"
      ],
      "metadata": {
        "id": "QjF55neQUQ1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "category_mapping = get_category_mapping()\n",
        "category_mapping.to_csv(\"category_mapping.csv\")"
      ],
      "metadata": {
        "id": "XzcDOuw_US_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_df = pd.read_csv('final_merged_df.csv')\n",
        "full_df = full_df[['videoID','category_name','views_count','duration','pushlishAt','channelID','region','categoryID','subscriberCount','videoCount','viewCount']]\n",
        "full_df.shape"
      ],
      "metadata": {
        "id": "6u70d-MgUU7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_duration_to_minutes(duration_str):\n",
        "    try:\n",
        "        duration = isodate.parse_duration(duration_str)\n",
        "        return round(duration.total_seconds()/60,0)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "df['duration_clean'] = df['duration'].apply(parse_duration_to_minutes).astype('int')\n",
        "df['duration_clean']"
      ],
      "metadata": {
        "id": "Z7hURfMfUW8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['pushlishAt'] = pd.to_datetime(df['pushlishAt'], errors='coerce')\n",
        "df['publish_year'] = df['pushlishAt'].dt.year\n",
        "df['publish_month'] = df['pushlishAt'].dt.month_name()\n",
        "df['publish_day'] = df['pushlishAt'].dt.day_name()\n",
        "df['publish_hour'] = df['pushlishAt'].dt.hour\n",
        "df['publish_time'] = df['pushlishAt'].dt.time"
      ],
      "metadata": {
        "id": "38i4AtYiUbnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'videoID':'video_id',\n",
        "                        'views_count':'video_views',\n",
        "                        'pushlishAt':'publish_datetime',\n",
        "                        'channelID':'channel_id',\n",
        "                        'subscriberCount':\"subscribers\",\n",
        "                        'videoCount':'channel_videos',\n",
        "                        'viewCount':'channel_views',\n",
        "                        'duration_clean':'duration_mins'})"
      ],
      "metadata": {
        "id": "DNla2eKnUdv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### average video views by video length\n",
        "\n",
        "#### creating the buckets for the length of vids (mins)\n",
        "bins = [0, 2, 5, 10, 20, 30, 60, 120]\n",
        "labels = ['<2', '2-5', '5-10', '10-20', '20-30', '30-60', '60+']\n",
        "df['length_bin'] = pd.cut(df['duration_mins'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "### calculating the average views per bucket\n",
        "length_views = df.groupby('length_bin')['video_views'].mean().reset_index()\n",
        "\n",
        "### plot - did fiddle with the figsize\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.barplot(data=length_views, x='length_bin', y='video_views', color='lightblue')\n",
        "plt.title('Average Video Views by Video Length')\n",
        "plt.xlabel('Video Length (minutes)')\n",
        "plt.ylabel('Average Views')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r-9AdHUJUftO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### average video views by length and by category\n",
        "\n",
        "bins = [0, 2, 5, 10, 20, 30, 60, 120]\n",
        "labels = ['<2', '2-5', '5-10', '10-20', '20-30', '30-60', '60+'] ### again - bin video bucket lengths\n",
        "df['length_bin'] = pd.cut(df['duration_mins'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "length_cat_views = df.groupby(['category_name', 'length_bin'])['video_views'].mean().reset_index() ### calculating the average views per bucket and category\n",
        "\n",
        "plt.figure(figsize=(14,8))\n",
        "sns.lineplot(data=length_cat_views, x='length_bin', y='video_views', hue='category_name', marker='o', palette='tab20')\n",
        "plt.title('Average Video Views by Video Length and Category')\n",
        "plt.xlabel('Video Length (minutes)')\n",
        "plt.ylabel('Average Views')\n",
        "plt.legend(title='Category')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qjImHas-Uks1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creating a summary table to be used\n",
        "### for the number of videos per channel by subscriber bin\n",
        "\n",
        "### definfing the subscriber bins\n",
        "bins = [0, 1_000, 10_000, 20_000, 50_000, 100_000, float('inf')]\n",
        "labels = ['<1k', '1k–10k', '10k–20k', '20k–50k', '50k–100k', '100k+']\n",
        "df['subscriber_bucket'] = pd.cut(df['subscribers'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "### grouping them by bucket and figuring out the mean and median channel video count\n",
        "grouped = df.groupby('subscriber_bucket')['channel_videos']\n",
        "\n",
        "average_videos = grouped.mean().round(1)\n",
        "median_videos = grouped.median().round(1)\n",
        "count_channels = df.groupby('subscriber_bucket')['channel_id'].nunique()  # Optional: how many unique channels per bucket\n",
        "\n",
        "### combinging into one summary table\n",
        "summary = pd.DataFrame({\n",
        "    'Avg Videos': average_videos,\n",
        "    'Median Videos': median_videos,\n",
        "    'Unique Channels': count_channels\n",
        "})\n",
        "\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "Hc1ksGuvUnfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### the bar chart for the number of videos per channel by subscriber bucket\n",
        "\n",
        "\n",
        "avg = summary['Avg Videos']\n",
        "median = summary['Median Videos']\n",
        "labels = summary.index.tolist()\n",
        "\n",
        "#### setting the positions\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "#### plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars1 = ax.bar(x - width/2, avg, width, label='Average', color='#1f77b4')\n",
        "bars2 = ax.bar(x + width/2, median, width, label='Median', color='#ff7f0e')\n",
        "\n",
        "### labels/titles\n",
        "ax.set_ylabel('Number of Videos')\n",
        "ax.set_xlabel('Subscriber Buckets')\n",
        "ax.set_title('Number of Videos per Channel by Subscriber Bucket')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "# wanted to add the value to the top of each bar\n",
        "def add_labels(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.0f}',\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "add_labels(bars1)\n",
        "add_labels(bars2)\n",
        "\n",
        "### ensuring layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "66xFq8hTUt83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### finding the channel information\n",
        "\n",
        "API_KEY = 'AIzaSyCRZFaoWaCVpjuoEIman7cowc-9lxJsiAI'  ### seeting up the API stuff\n",
        "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
        "\n",
        "channel_ids = all_videos['channelID'].unique() ### finding unique channelID from the all_videos file\n",
        "\n",
        "channel_stats = [] ### somewhere to store all the channel stats\n",
        "\n",
        "for i in range(0, len(channel_ids), 50):  ### API handles up to 50 IDs per request\n",
        "    batch = channel_ids[i:i+50]\n",
        "\n",
        "    try:\n",
        "        response = youtube.channels().list(\n",
        "            part='statistics',\n",
        "            id=','.join(batch)\n",
        "        ).execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            stats = item['statistics']\n",
        "            channel_stats.append({\n",
        "                'channelID': item['id'],\n",
        "                'subscriberCount': int(stats.get('subscriberCount', 0)),\n",
        "                'videoCount': int(stats.get('videoCount', 0)),\n",
        "                'viewCount': int(stats.get('viewCount', 0))\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in batch {i}-{i+50}: {e}\")\n",
        "        continue"
      ],
      "metadata": {
        "id": "haDqUSgRUw6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channel_merge = pd.merge(all_videos, channel_df[['channelID', 'subscriberCount', 'videoCount', 'viewCount']], on='channelID', how='left')"
      ],
      "metadata": {
        "id": "HWTujxmbUzNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_key =\"AIzaSyDx0c31T44Ioojox_EmvtCnzw7127XzQD4\"\n",
        "url = 'https://www.googleapis.com/youtube/v3/search'\n",
        "regions = ['US', 'GB', 'DE']\n",
        "\n",
        "for region in regions:\n",
        "    print(f\"\\n Region: {region}\")\n",
        "\n",
        "params = {'key':my_key,\n",
        "        'q': 'python',\n",
        "        'type': 'video',\n",
        "        'part': 'snippet',\n",
        "        'maxResults': 5,\n",
        "        \"regionCode\": \"US\",\n",
        "        'relevanceLanguage': 'en'\n",
        "        }\n",
        "response = requests.get('https://www.googleapis.com/youtube/v3/search', params=params)\n",
        "data = response.json()\n",
        "\n",
        "for item in data.get('items', []):\n",
        "        title = item['snippet']['title']\n",
        "        print(f\":clapper: {title}\")"
      ],
      "metadata": {
        "id": "6pVM_C9aU1_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_key =\"AIzaSyDx0c31T44Ioojox_EmvtCnzw7127XzQD4\"\n",
        "url = 'https://www.googleapis.com/youtube/v3/search'\n",
        "regions = ['US', 'GB', 'DE']\n",
        "\n",
        "params = {'key':my_key,\n",
        "        'q': 'python',\n",
        "        'type': 'video',\n",
        "        'part': 'snippet',\n",
        "        'maxResults': 5\n",
        "        }\n",
        "response = requests.get(url,params)\n",
        "response.json()"
      ],
      "metadata": {
        "id": "j4snyr2cU4aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.googleapis.com/youtube/v3/search\"\n",
        "my_key = 'AIzaSyDx0c31T44Ioojox_EmvtCnzw7127XzQD4'\n",
        "regions = ['US', 'GB', 'DE']\n",
        "for region in regions:\n",
        "    params = {'key':my_key,\n",
        "            'q': 'python',\n",
        "            'type': 'video',\n",
        "            'part': 'snippet',\n",
        "            'maxResults': 5,\n",
        "            'regionCode': region,\n",
        "            'relevanceLanguage': 'en'\n",
        "            }\n",
        "    response = requests.get(url,params)"
      ],
      "metadata": {
        "id": "v_cv9o0bU6RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from googleapiclient.discovery import build\n",
        "import time\n",
        "\n",
        "my_key = 'AIzaSyDx0c31T44Ioojox_EmvtCnzw7127XzQD4'\n",
        "#creates a service object: youtube\n",
        "youtube = build('youtube','v3',developerKey=my_key)\n",
        "\n",
        "categories_ids = ['1', '10', '17', '20'] # Define video category IDs (example: 1 = Film & Animation, 10 = Music, etc.)\n",
        "\n",
        "def get_videoIDs(countries,categories_ids = categories_ids):\n",
        "    Videos = []\n",
        "    for country in countries:   # us\n",
        "        for category in categories_ids:  # category = 1\n",
        "            response = youtube.search().list(\n",
        "                part = \"id,snippet\",\n",
        "                maxResults=50,\n",
        "                regionCode = country,\n",
        "                relevanceLanguage = 'en',\n",
        "                type=\"video\",\n",
        "                videoCategoryId = category).execute()\n",
        "            for item in response['items']:\n",
        "                Videos.append(item['id']['videoId'])\n",
        "            time.sleep(1)\n",
        "    return Videos\n",
        "get_videoIDs(['US','JP','GB','NL'])"
      ],
      "metadata": {
        "id": "pzxGTP8MU9S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_ids(countries, categories_ids=['1'], max_results=2000):\n",
        "    video_ids = []\n",
        "    for country in countries:\n",
        "        for category in categories_ids:\n",
        "            page_token = None\n",
        "            while len(video_ids) < max_results:\n",
        "                response = youtube.search().list(\n",
        "                    part=\"id\",\n",
        "                    regionCode=country,\n",
        "                    relevanceLanguage='en',\n",
        "                    type=\"video\",\n",
        "                    videoCategoryId=category,\n",
        "                    maxResults=50,\n",
        "                    pageToken=page_token\n",
        "                ).execute()\n",
        "                for item in response.get('items', []):\n",
        "                    video_id = item['id'].get('videoId')\n",
        "                    if video_id:\n",
        "                        video_ids.append(video_id)\n",
        "                        if len(video_ids) >= max_results:\n",
        "                            break\n",
        "                page_token = response.get('nextPageToken')\n",
        "                if not page_token:\n",
        "                    break  # No more pages\n",
        "                time.sleep(1)  # Avoid rate limits\n",
        "    return video_ids\n",
        "get_video_ids([\"GB\"])"
      ],
      "metadata": {
        "id": "kmOwCnOEU_bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "API_KEY = \"AIzaSyDx0c31T44Ioojox_EmvtCnzw7127XzQD4\"\n",
        "search_url = \"https://www.googleapis.com/youtube/v3/search\"\n",
        "channels_url = \"https://www.googleapis.com/youtube/v3/channels\"\n",
        "regions = ['US', 'GB', 'DE']\n",
        "keywords = ['python', 'gaming', 'travel', 'music', 'esports', 'cover', 'guitar',\n",
        "            'how to', 'workout', 'fitness', 'vlog', 'adventure', 'recipes',\n",
        "            'funny', 'tech', 'investing', 'trailer', 'football']\n",
        "max_results_per_region = 50\n",
        "channel_ids = set()\n",
        "for keyword in keywords:\n",
        "    for region in regions:\n",
        "        params = {\n",
        "            'key': API_KEY,\n",
        "            'q': keyword,\n",
        "            'type': 'video',\n",
        "            'part': 'snippet',\n",
        "            'maxResults': max_results_per_region,\n",
        "            'regionCode': region,\n",
        "            'relevanceLanguage': 'en'\n",
        "        }\n",
        "        response = requests.get(search_url, params=params).json()\n",
        "        for item in response.get('items', []):\n",
        "            channel_id = item['snippet']['channelId']\n",
        "            channel_ids.add(channel_id)\n",
        "print(f\"Collected {len(channel_ids)} IDs.\")"
      ],
      "metadata": {
        "id": "z0RlZwklVBpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_codes = [\n",
        "    'DK', 'FI', 'NO', 'PL', 'PT', 'CZ', 'HU', 'IE', 'NZ', 'SG',\n",
        "    'MY', 'PH', 'TH', 'TW', 'VN', 'IL', 'SA', 'AE', 'ZA', 'EG',\n",
        "   ]"
      ],
      "metadata": {
        "id": "JnWhEjM8VCdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube = build('youtube','v3',developerKey=my_key)"
      ],
      "metadata": {
        "id": "l2alzXTqVEcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filtered_videos(region_codes):\n",
        "    filtered_videos = {\n",
        "        'videoID': [],\n",
        "        'title': [],\n",
        "        'views_count': [],\n",
        "        'duration': [],\n",
        "        'pushlishAt': [],\n",
        "        'channelID': [],\n",
        "        'description': [],\n",
        "        'region': []\n",
        "    }\n",
        "\n",
        "    for region in region_codes:\n",
        "        response = youtube.videos().list(\n",
        "            part=\"snippet,statistics,contentDetails\",\n",
        "            chart=\"mostPopular\",\n",
        "            regionCode=region,\n",
        "            maxResults=50\n",
        "        ).execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            duration = item['contentDetails']['duration']\n",
        "\n",
        "            # Skip videos that are only seconds long\n",
        "            if duration.startswith('PT') and 'M' not in duration and 'H' not in duration:\n",
        "                continue\n",
        "\n",
        "            filtered_videos['videoID'].append(item['id'])\n",
        "            filtered_videos['title'].append(item['snippet']['title'])\n",
        "            filtered_videos['views_count'].append(int(item['statistics'].get('viewCount', 0)))\n",
        "            filtered_videos['duration'].append(duration)\n",
        "            filtered_videos['pushlishAt'].append(item['snippet']['publishedAt'])\n",
        "            filtered_videos['channelID'].append(item['snippet']['channelId'])\n",
        "            filtered_videos['description'].append(item['snippet']['description'])\n",
        "            filtered_videos['region'].append(region)\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(filtered_videos)\n",
        "    return df"
      ],
      "metadata": {
        "id": "vAKCscWRVGkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import isodate\n",
        "\n",
        "def parse_duration_to_minutes(duration_str):\n",
        "    try:\n",
        "        duration = isodate.parse_duration(duration_str)\n",
        "        return duration.total_seconds() / 60\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "df['duration_minutes'] = df['duration'].apply(parse_duration_to_minutes)\n",
        "\n",
        "df.rename(columns={'pushlishAt': 'publishAt'}, inplace=True)\n",
        "df['publishAt'] = pd.to_datetime(df['publishAt'], errors='coerce')\n",
        "df['publish_date'] = df['publishAt'].dt.date\n",
        "df['publish_day'] = df['publishAt'].dt.day_name()"
      ],
      "metadata": {
        "id": "QeraMA4aVJaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import isodate\n",
        "\n",
        "def parse_duration_to_minutes(duration_str):\n",
        "    try:\n",
        "        duration = isodate.parse_duration(duration_str)\n",
        "        return duration.total_seconds() / 60\n",
        "    except:\n",
        "        return None  # fallback in case of bad format\n",
        "\n",
        "def get_filtered_videos(region_codes):\n",
        "    filtered_videos = {\n",
        "        'videoID': [],\n",
        "        'title': [],\n",
        "        'views_count': [],\n",
        "        'duration': [],\n",
        "        'publishAt': [],\n",
        "        'channelID': [],\n",
        "        'description': [],\n",
        "        'region': []\n",
        "    }\n",
        "\n",
        "    for region in region_codes:\n",
        "        response = youtube.videos().list(\n",
        "            part=\"snippet,statistics,contentDetails\",\n",
        "            chart=\"mostPopular\",\n",
        "            regionCode=region,\n",
        "            maxResults=50\n",
        "        ).execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            duration = item['contentDetails']['duration']\n",
        "\n",
        "            # Skip videos that are only seconds long\n",
        "            if duration.startswith('PT') and 'M' not in duration and 'H' not in duration:\n",
        "                continue\n",
        "\n",
        "            filtered_videos['videoID'].append(item['id'])\n",
        "            filtered_videos['title'].append(item['snippet']['title'])\n",
        "            filtered_videos['views_count'].append(int(item['statistics'].get('viewCount', 0)))\n",
        "            filtered_videos['duration'].append(duration)\n",
        "            filtered_videos['publishAt'].append(item['snippet']['publishedAt'])\n",
        "            filtered_videos['channelID'].append(item['snippet']['channelId'])\n",
        "            filtered_videos['description'].append(item['snippet']['description'])\n",
        "            filtered_videos['region'].append(region)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(filtered_videos)\n",
        "\n",
        "    # Convert duration to minutes\n",
        "    df['duration_minutes'] = df['duration'].apply(parse_duration_to_minutes)\n",
        "\n",
        "# Round to nearest minute (and allow missing values)\n",
        "    df['duration_minutes'] = df['duration_minutes'].round(0).astype('Int64')\n",
        "\n",
        "    # Convert pushlishAt to datetime\n",
        "    df['publishAt'] = pd.to_datetime(df['publishAt'], errors='coerce')\n",
        "\n",
        "    # Extract date and day of week\n",
        "    df['publish_date'] = df['publishAt'].dt.date\n",
        "    df['publish_day'] = df['publishAt'].dt.day_name()\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "nHs8xl2aVMXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_duration_to_minutes(duration_str):\n",
        "    try:\n",
        "        duration = isodate.parse_duration(duration_str)\n",
        "        return duration.total_seconds() / 60\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def clean_youtube_data(df):\n",
        "    # Fix common misspelling if needed\n",
        "    if 'pushlishAt' in df.columns and 'publishAt' not in df.columns:\n",
        "        df.rename(columns={'pushlishAt': 'publishAt'}, inplace=True)\n",
        "\n",
        "    # Convert duration to minutes\n",
        "    df['duration_minutes'] = df['duration'].apply(parse_duration_to_minutes)\n",
        "    df['duration_minutes'] = df['duration_minutes'].round(0).astype('Int64')\n",
        "\n",
        "    # Convert publishAt to datetime\n",
        "    df['publishAt'] = pd.to_datetime(df['publishAt'], errors='coerce')\n",
        "\n",
        "    # Extract publish date and weekday\n",
        "    df['publish_date'] = df['publishAt'].dt.date\n",
        "    df['publish_day'] = df['publishAt'].dt.day_name()\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "BVmlZtTJVRxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_videos(region_codes):\n",
        "    filtered_videos = {\n",
        "            'videoID': [],\n",
        "            'title': [],\n",
        "            'views_count': [],\n",
        "            'duration': [],\n",
        "            'pushlishAt': [],\n",
        "            'channelID': [],\n",
        "            'description': [],\n",
        "            'region':[],\n",
        "            'categoryID':[]\n",
        "        }\n",
        "    for region in region_codes:\n",
        "        response = youtube.videos().list(\n",
        "                part=\"snippet,statistics,contentDetails\",\n",
        "                chart=\"mostPopular\",\n",
        "                regionCode=region,\n",
        "                maxResults=50\n",
        "            ).execute()\n",
        "        for item in response['items']:\n",
        "            duration = item['contentDetails']['duration']\n",
        "            if duration.startswith('PT') and 'M' not in duration and 'H' not in duration:\n",
        "                continue\n",
        "            filtered_videos['videoID'].append(item['id'])\n",
        "            filtered_videos['title'].append(item['snippet']['title'])\n",
        "            filtered_videos['views_count'].append(int(item['statistics'].get('viewCount', 0)))\n",
        "            filtered_videos['duration'].append(duration)\n",
        "            filtered_videos['pushlishAt'].append(item['snippet']['publishedAt'])\n",
        "            filtered_videos['channelID'].append(item['snippet']['channelId'])\n",
        "            filtered_videos['description'].append(item['snippet']['description'])\n",
        "            filtered_videos['region'].append(region)\n",
        "            filtered_videos['categoryID'].append(item['snippet']['categoryId'])\n",
        "    df = pd.DataFrame(filtered_videos)\n",
        "    return df"
      ],
      "metadata": {
        "id": "QYNF_4h9VVi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by region and category, calculate average views\n",
        "df_region_views = df.groupby(['region', 'category_name'])['video_views'].mean().reset_index()\n",
        "\n",
        "# Find the category with the highest average views in each region\n",
        "df_top_categories = grouped.loc[grouped.groupby('region')['video_views'].idxmax()].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "QBPWOOltVYQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos_per_channel = df.groupby('channel_id').size().reset_index(name='chanel_videos')\n",
        "channel_stats = videos_per_channel.merge(df, on='channel_id', how='left')\n",
        "bins = [0, 1000, 10000, 100000, 1000000, 10000000, float('inf')]\n",
        "labels = ['0-1k', '1k-10k', '10k-100k', '100k-1M', '1M-10M', '10M+']\n",
        "channel_stats['sub_bucket'] = pd.cut(channel_stats['subscribers'], bins=bins, labels=labels)\n",
        "avg_videos_per_bucket = channel_stats.groupby('sub_bucket')['channel_videos'].mean().reset_index()\n",
        "print(avg_videos_per_bucket)"
      ],
      "metadata": {
        "id": "cU8I-az8VauX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Optional: Convert categoryID to string if needed for x-axis labels\n",
        "top_categories['category_name'] = top_categories['category_name'].astype(str)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(30, 10))\n",
        "bars = plt.bar(top_categories['region'], top_categories['video_views'])\n",
        "\n",
        "# Add category labels on top of each bar\n",
        "for i, row in top_categories.iterrows():\n",
        "    plt.text(i, row['video_views'] + (row['video_views'] * 0.01),\n",
        "             f\"{row['category_name']}\", ha='center', fontsize=10)\n",
        "\n",
        "# Customize the chart\n",
        "plt.xlabel(\"Region\")\n",
        "plt.ylabel(\"Average Views\")\n",
        "plt.title(\"Top Viewed Video Category per Region\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig('top_categories_by_region.png', dpi=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2QjxWXo9Vc7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_categories['category_name'] = top_categories['category_name'].astype(str)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(30, 10))\n",
        "bars = plt.bar(top_categories['region'], top_categories['video_views'])\n",
        "\n",
        "# Add category labels on top of each bar\n",
        "for i, row in top_categories.iterrows():\n",
        "    plt.text(i, row['video_views'] + (row['video_views'] * 0.01),\n",
        "             f\"{row['category_name']}\", ha='center', fontsize=10)\n",
        "\n",
        "# Customize the chart\n",
        "plt.xlabel(\"Region\")\n",
        "plt.ylabel(\"Average Views\")\n",
        "plt.title(\"Top Viewed Video Category per Region\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig('top_categories_by_region.png', dpi=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_CofeyxxVgo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(avg_videos_per_bucket['sub_bucket'], avg_videos_per_bucket['channel_videos'])\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel('Subscriber Buckets')\n",
        "plt.ylabel('Average Number of Videos')\n",
        "plt.title('Average Number of Videos per Subscriber Bucket')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Show the graph\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eaBrRRQGVii7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(30, 10))\n",
        "\n",
        "# Create barplot\n",
        "sns.barplot(\n",
        "    data=top_categories,\n",
        "    x='region',\n",
        "    y='video_views',\n",
        "    color='skyblue'\n",
        ")\n",
        "\n",
        "# Add category labels on top of each bar\n",
        "for i, row in top_categories.iterrows():\n",
        "    plt.text(\n",
        "        i,\n",
        "        row['video_views'] + (row['video_views'] * 0.01),\n",
        "        row['category_name'],\n",
        "        ha='center',\n",
        "        fontsize=10\n",
        "    )\n",
        "\n",
        "# Customize the chart\n",
        "plt.xlabel(\"Region\")\n",
        "plt.ylabel(\"Average Views\")\n",
        "plt.title(\"Top Viewed Video Category per Region\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save as PNG\n",
        "plt.savefig('top_categories_by_region.png', dpi=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8oMU_eyHVlVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 20))  # Adjust height for spacing\n",
        "\n",
        "sns.barplot(\n",
        "    data=top_categories,\n",
        "    y='region',  # Switched from x to y\n",
        "    x='video_views',\n",
        "    color='skyblue'\n",
        ")\n",
        "\n",
        "# Add category labels next to each bar\n",
        "for i, row in top_categories.iterrows():\n",
        "    plt.text(\n",
        "        row['video_views'] + (row['video_views'] * 0.01),\n",
        "        i,\n",
        "        row['category_name'],\n",
        "        va='center',\n",
        "        fontsize=10\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"Average Views\")\n",
        "plt.ylabel(\"Region\")\n",
        "plt.title(\"Top Viewed Video Category per Region\")\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig('top_categories_by_region_horizontal.png', dpi=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H2FSNDfuVn6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create horizontal barplot\n",
        "sns.barplot(\n",
        "    data=avg_videos_per_bucket,\n",
        "    y='sub_bucket',         # <- y becomes the categorical axis\n",
        "    x='channel_videos',     # <- x becomes the numerical axis\n",
        "    color='skyblue'\n",
        ")\n",
        "\n",
        "# Labels and title\n",
        "plt.ylabel('Subscriber Buckets')\n",
        "plt.xlabel('Average Number of Videos')\n",
        "plt.title('Average Number of Videos per Subscriber Bucket')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Final layout and show\n",
        "plt.tight_layout()\n",
        "plt.savefig('average_number_videos_bucket_horizontal.png', dpi=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w_mzhSxMVp1A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
